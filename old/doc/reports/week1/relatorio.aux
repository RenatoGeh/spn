\relax 
\providecommand\hyper@newdestlabel[2]{}
\catcode `"\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@sortscheme{nty}
\abx@aux@cite{bayes-net-darwiche}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\select@language{brazilian}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\select@language{brazilian}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\select@language{brazilian}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\select@language{brazilian}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}Atividades realizadas na semana}{1}{section.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ Durante a semana foram lidos os seguintes t\IeC {\'o}picos do livro \textit  {Modeling and Reasoning with Bayesian Networks}\cite {bayes-net-darwiche}: }{1}{paragraph*.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}Defini\IeC {\c c}\IeC {\~a}o das atividades}{1}{section.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ Foram estudados o processo de se compilar Redes Bayesianas em circuitos aritm\IeC {\'e}ticos, algumas nota\IeC {\c c}\IeC {\~o}es usadas em Redes Bayesianas, a defini\IeC {\c c}\IeC {\~a}o de uma \textit  {network polynomial}, algumas propriedades de Redes Bayesianas e diferencia\IeC {\c c}\IeC {\~a}o de uma rede a partir de uma evid\IeC {\^e}ncia. }{1}{paragraph*.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ Esta se\IeC {\c c}\IeC {\~a}o ser\IeC {\'a} dividida em subse\IeC {\c c}\IeC {\~o}es para cada subt\IeC {\'o}pico citado na se\IeC {\c c}\IeC {\~a}o anterior. Cada subse\IeC {\c c}\IeC {\~a}o \IeC {\'e} um resumo do que foi estudado em cada t\IeC {\'o}pico, contendo os assuntos mais importantes para o projeto. }{1}{paragraph*.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Introduction}{1}{subsection.2.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ Aqui apresentaremos algumas nota\IeC {\c c}\IeC {\~o}es usadas em Redes Bayesianas - e que podem ser extendidas para outros Modelos Gr\IeC {\'a}ficos Probabil\IeC {\'\i }sticos (PGM). }{1}{paragraph*.4}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Uma Rede Bayesiana $A \to B$. Em Redes Bayesianas uma aresta representa uma depend\IeC {\^e}ncia. No caso da imagem $B$ depende de $A$. As CPTs associadas a esse grafo est\IeC {\~a}o em Tabela 1 e Tabela 2.\relax }}{1}{figure.caption.5}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  e Tabela 2\relax }}{1}{table.caption.6}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ Antes de come\IeC {\c c}armos com circuitos aritm\IeC {\'e}ticos, vamos primeiro apresentar algumas defini\IeC {\c c}\IeC {\~o}es importantes. }{2}{paragraph*.7}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ Chamamos de CPT (Conditional Probability Table) as tabelas que representam as probabilidades de uma rede (ex.: as CPTs da Rede Bayesiana na Figura 1 s\IeC {\~a}o as Tabelas 1 e 2). Pode-se claramente ver que para $n$ n\IeC {\'o}s de uma Rede Bayesiana, precisamos de uma quantidade exponencial $2^n$ de probabilidades para representar cada inst\IeC {\^a}ncia de vari\IeC {\'a}veis. }{2}{paragraph*.8}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ Chamamos de MPE (Most Probable Explanation) a inst\IeC {\^a}ncia mais prov\IeC {\'a}vel de vari\IeC {\'a}veis que aceitam uma evid\IeC {\^e}ncia. Mais formalmente dizemos que: }{2}{paragraph*.9}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ Chamamos de MAP (Maximum A Posteriori hypothesis) quando a probabilidade de uma certa inst\IeC {\^a}ncia \IeC {\'e} maximal. }{2}{paragraph*.10}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ $M$ tamb\IeC {\'e}m \IeC {\'e} chamado de vari\IeC {\'a}veis MAP. MPE \IeC {\'e} uma MAP quando as vari\IeC {\'a}veis MAP incluem todas as vari\IeC {\'a}veis da rede. }{2}{paragraph*.11}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ Agora que temos uma base podemos voltar para circuitos aritm\IeC {\'e}ticos. Dado um circuito aritm\IeC {\'e}tico que representa uma Rede Bayesiana, teremos dois tipos de entradas: vari\IeC {\'a}veis $\theta $, que chamaremos de \textit  {par\IeC {\^a}metros}, e as vari\IeC {\'a}veis $\lambda $, que chamaremos de \textit  {indicadores}. Par\IeC {\^a}metros s\IeC {\~a}o valorados de acordo com a CPT da rede, enquanto indicadores s\IeC {\~a}o valorados de acordo com a evid\IeC {\^e}ncia. Nas pr\IeC {\'o}ximas subse\IeC {\c c}\IeC {\~o}es veremos que podemos ter duas passagens pelo circuito. Uma em que vamos de baixo para cima (bottom-up) para calcular a probabilidade de uma dada evid\IeC {\^e}ncia, e outra em que vamos de cima para baixo (top-down), chamada de \textit  {differentiation pass} para calcularmos as derivadas parciais de cada entrada do circuito. }{2}{paragraph*.12}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Circuit semantics}{2}{subsection.2.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ Ao compilarmos um circuito aritm\IeC {\'e}tico de uma Rede Bayesiana estamos representando, de forma compacta, a distribui\IeC {\c c}\IeC {\~a}o de probabilidade induzida da rede. No caso da Figura 1, a distribui\IeC {\c c}\IeC {\~a}o de probabilidade est\IeC {\'a} representada na Tabela 3. }{2}{paragraph*.13}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces \relax }}{2}{table.caption.14}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ Multiplicando cada $Pr(A, B)$ com as suas respectivas vari\IeC {\'a}veis indicadoras temos que: }{3}{paragraph*.15}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces \relax }}{3}{table.caption.16}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ Somando todas as probabilidades da distribui\IeC {\c c}\IeC {\~a}o temos: }{3}{paragraph*.17}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ Chamamos a fun\IeC {\c c}\IeC {\~a}o $f$ de \textit  {network polynomial}, que representa a distribui\IeC {\c c}\IeC {\~a}o de probabilidade da rede na Figura 1. Para computar a probabilidade dada qualquer evid\IeC {\^e}ncia $e$, definimos cada vari\IeC {\'a}vel indicadora de forma consistente com a evid\IeC {\^e}ncia. Vamos definir o que significa definir uma vari\IeC {\'a}vel de forma consistente com uma evid\IeC {\^e}ncia: }{3}{paragraph*.18}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ Portanto, se por exemplo tivermos evid\IeC {\^e}ncia $e=\overline  {a}$, teremos na \textit  {network polynomial} da Figura 1 os seguintes indicadores: $\lambda _{a}=0, \lambda _{\overline  {a}}=1, \lambda _{b}=1, \lambda _{\overline  {b}}=1$. Neste exemplo, o valor de $f$ seria: }{3}{paragraph*.19}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ Como a \textit  {network polynomial} de uma rede \IeC {\'e} a distribui\IeC {\c c}\IeC {\~a}o de probabilidade da rede, ent\IeC {\~a}o seu tamanho \IeC {\'e} exponencial. O circuito aritm\IeC {\'e}tico \IeC {\'e} uma representa\IeC {\c c}\IeC {\~a}o compacta de $f$. Em alguns casos $f$ n\IeC {\~a}o pode ser limitado, enquanto que o circuito pode. }{3}{paragraph*.20}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ Vamos definir formalmente uma \textit  {network polynomial}, mas antes vamos definir algumas nota\IeC {\c c}\IeC {\~o}es. Dizemos que $\theta _{x|\textbf  {u}} \sim \textbf  {z}$ para dizer que $x\textbf  {u}$ \IeC {\'e} consistente com $\textbf  {z}, x\textbf  {u} \sim \textbf  {z}$. Portanto, $\DOTSB \prod@ \slimits@ _{\theta _{x|\textbf  {u}} \sim \textbf  {z}} \theta _{x|\textbf  {u}}$ denota o produto de todos os par\IeC {\^a}metros $\theta _{x|\textbf  {u}}$ onde $x\textbf  {u}$ seja consistente com $\textbf  {z}$. A mesma nota\IeC {\c c}\IeC {\~a}o aplica-se a $\lambda _x \sim \textbf  {z}$. }{3}{paragraph*.21}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Circuit propagation}{4}{subsection.2.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ Nesta subse\IeC {\c c}\IeC {\~a}o definiremos o que s\IeC {\~a}o derivadas parciais e sua utilidade em Redes Bayesianas. }{4}{paragraph*.22}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ A derivada parcial de uma vari\IeC {\'a}vel representa o quanto a mudan\IeC {\c c}a de uma vari\IeC {\'a}vel impacta na sa\IeC {\'\i }da final da rede. Portanto, seja $\lambda _{\overline  {a}}=0$ e sua derivada parcial $\partial {f}/\partial {\lambda _{\overline  {a}}} = 0.4$, e dada evid\IeC {\^e}ncia $e=a\overline  {c}$ e seja o valor final de $f(e)=0.1$, ao mudarmos o valor de $\lambda _{\overline  {a}}=1$, estaremos na realidade mudando a evid\IeC {\^e}ncia de $a\overline  {c}$ para $\overline  {c}$, e portanto teremos um valor final de 0.5 ao inv\IeC {\'e}s de 0.1, que representa justamente $f(\overline  {c})$. Como pode-se notar, ter a derivada parcial evita termos de computar toda vez a rede, j\IeC {\'a} que temos as diferen\IeC {\c c}as no pr\IeC {\'o}prio circuito. }{4}{paragraph*.23}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ Vamos definir uma nota\IeC {\c c}\IeC {\~a}o de mudan\IeC {\c c}a de evid\IeC {\^e}ncia. Sejam uma evid\IeC {\^e}ncia $e$ e $X$ um conjunto de vari\IeC {\'a}veis. Dizemos que $e-X$ \IeC {\'e} todos os elementos de $e$ menos aqueles que s\IeC {\~a}o equivalentes a qualquer elemento do conjunto $X$. Por exemplo, se $e=ab\overline  {c}$, ent\IeC {\~a}o $e-A=b\overline  {c}$ e $e-AC=b$. }{4}{paragraph*.24}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Evaluation and differentiation passes}{4}{subsection.2.4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ Na subse\IeC {\c c}\IeC {\~a}o 12.3.1 do livro vimos como implementar as passagens \textit  {top-down} e \textit  {bottom-up}. Em seguida analisamos a complexidade das duas passagens. N\IeC {\~a}o vamos citar os algoritmos neste relat\IeC {\'o}rio pois n\IeC {\~a}o \IeC {\'e} de muita import\IeC {\^a}ncia para o projeto. No entanto, \IeC {\'e} interessante citar as complexidades dos algoritmos. }{4}{paragraph*.25}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ No algoritmo de \textit  {bottom-up}, a complexidade em tempo foi linear ao tamanho do circuito, onde o tamanho foi definido como o n\IeC {\'u}mero de arestas no circuito. }{4}{paragraph*.26}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ No algoritmo de \textit  {top-down}, a princ\IeC {\'\i }pio o algoritmo era linear se o n\IeC {\'u}mero de n\IeC {\'o}s crian\IeC {\c c}as era limitado. Por\IeC {\'e}m, no segundo algoritmo garantimos que fosse linear sempre, j\IeC {\'a} que se um n\IeC {\'o} era zero, n\IeC {\~a}o guard\IeC {\'a}vamos os n\IeC {\'o}s crian\IeC {\c c}as dele. }{4}{paragraph*.27}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3}Conclus\IeC {\~a}o}{4}{section.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{ Estudou-se algumas nota\IeC {\c c}\IeC {\~o}es em Redes Bayesianas que s\IeC {\~a}o indispens\IeC {\'a}veis para aprender Sum-Product Networks. Al\IeC {\'e}m disso, o estudo de \textit  {network polynomial}, que \IeC {\'e} bastante presente em PGMs \IeC {\'e} um requerimento importante para SPNs. Tamb\IeC {\'e}m adquiriu-se uma no\IeC {\c c}\IeC {\~a}o b\IeC {\'a}sica de circuitos aritm\IeC {\'e}ticos e de como implementa-los. Um outro ponto importante foi diferencia\IeC {\c c}\IeC {\~a}o parcial de vari\IeC {\'a}veis, que evita termos de passar v\IeC {\'a}rias vezes pelo circuito quando mudamos a evid\IeC {\^e}ncia. }{4}{paragraph*.28}}
